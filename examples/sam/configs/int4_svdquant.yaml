# SAM Nunchaku Backbone W4A8 with SVDQuant Configuration
# 4-bit weights with low-rank compensation, 8-bit activations

quant:
  # Calibration settings
  calib:
    num_samples: 128
    batch_size: 1

  # Weight quantization - 4-bit with SVDQuant
  wgts:
    dtype: uint4
    zero_point: PostScale
    static: true
    group_shapes:
      - [1, 128]
    scale_dtypes:
      - torch.float16

    # GPTQ configuration
    enable_kernel_gptq: true
    kernel_gptq:
      damp_percentage: 0.01
      block_size: 128
      num_inv_tries: 250
      hessian_block_size: 512

    # SVDQuant: Low-rank branch for outlier compensation
    low_rank:
      rank: 32                      # Rank of low-rank branch
      compensate: true              # Compensate for quantization error
      exclusive: false              # Share low-rank across multiple tensors
      skips: []                     # No skips

    skip_patch_embed: true
    skip_first_block: false
    skip_last_block: false
    skip_decoder: false

    enable_calib_range: false

  # Input activation quantization - 8-bit
  ipts:
    dtype: uint8
    zero_point: PostScale
    static: false
    per_token: true
    group_shapes:
      - [1, -1]
    scale_dtypes:
      - torch.float16

    enable_calib_range: true
    calib_range:
      objective: TensorError
      strategy: GridSearch
      granularity: Group
      degree: 2.4
      num_grids: 100

  # Output activation quantization - 8-bit
  opts:
    dtype: uint8
    zero_point: PostScale
    static: false
    per_token: true
    group_shapes:
      - [1, -1]
    scale_dtypes:
      - torch.float16

    enable_calib_range: true
    calib_range:
      objective: TensorError
      strategy: GridSearch
      granularity: Group
      degree: 2.4
      num_grids: 100

  rotation:
    enabled: false

  smooth:
    enabled: false
