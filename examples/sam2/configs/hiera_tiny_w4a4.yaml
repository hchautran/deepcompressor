# SAM2 Hiera-Tiny W4A4 Quantization Configuration
# 4-bit weights, 4-bit activations

model:
  name: tiny
  device: cuda
  dtype: float16

cache:
  root: ./cache/sam2

quant:
  calib:
    path: /path/to/coco/val2017
    num_samples: 128
    batch_size: 1
    image_size: 1024
    seed: 42

  wgts:
    dtype: uint4
    group_shapes: [[1, 128]]
    kernel_gptq:
      damp_percentage: 0.01
      block_size: 128
      num_inv_tries: 200

  ipts:
    dtype: uint4
    group_shapes: [[1, -1]]
    static: false

  opts:
    dtype: null

  smooth:
    proj:
      granularity: Layer
      strategy: GridSearch
      num_grids: 20
      alpha: 0.5

  rotation:
    transforms: [hadamard]
    random: false

output:
  root: ./outputs/sam2
  job: hiera_tiny_w4a4

save_model: true
seed: 42
